# -*- coding: utf-8 -*-
"""spam mail filtering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eewBjFTXHyyL03caA8W5qNQeViLnmTQj
"""

import numpy as np
import pandas as pd
import sklearn
from sklearn import preprocessing
from sklearn.preprocessing import LabelEncoder,OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split 
from sklearn.feature_extraction.text import CountVectorizer 
from sklearn.tree import DecisionTreeClassifier
import imblearn
from imblearn.over_sampling import SMOTE 
import re
import pickle
import matplotlib.pyplot as plt
import nltk 
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer

df=pd.read_csv('/content/spam.csv',encoding="latin")
df

df.info()

df.isna().sum()

df.rename({"v1":"label","v2":"text"},inplace=True,axis=1)

df

le = LabelEncoder()
df['label'] = le.fit_transform(df['label'])

X = df['text']
y = df['label']

vectorizer = CountVectorizer()

X_transformed = vectorizer.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)

print("Before oversampling, count of label '1': {}".format(sum(y_train == 1)))
print("Before oversampling, count of label '0': {}".format(sum(y_train == 0)))

smote = SMOTE(random_state=42)

X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

print("After oversampling, count of label '1': {}".format(sum(y_resampled == 1)))
print("After oversampling, count of label '0': {}".format(sum(y_resampled == 0)))

nltk.download("stopwords")

corpus=[]
length=len(df)

for i in range(0, len(df)):
    text = re.sub('[^a-zA-Z0-9]', ' ', df['text'][i])
    text = text.lower()
    text = text.split()
    ps = PorterStemmer()
    stop_words = set(stopwords.words('english'))
    text = [ps.stem(word) for word in text if not word in stop_words]
    text = ' '.join(text)
    corpus.append(text)

corpus

cv=CountVectorizer(max_features=35000)
X=cv.fit_transform(corpus).toarray()

pickle.dump(cv, open('cv1.pkl','wb'))

df.describe()

df.shape
(5572,5)

df["label"].value_counts().plot(kind="bar",figsize=(12,6))
plt.xticks(np.arange(2),('Non spam','spam'),rotation=0);

X_bal = [[1, 2], [3, 4], [5, 6]]
names = ['label', 'text']

sc=StandardScaler()
X_bal_scaled = sc.fit_transform(X_bal)

print(X_bal_scaled)

X_bal_df = pd.DataFrame(X_bal_scaled, columns=names)
print(X_bal_df)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

# Create a decision tree classifier and fit it to the training data
clf = DecisionTreeClassifier()
clf.fit(X_train, y_train)

# Evaluate the accuracy of the model on the testing data
accuracy = clf.score(X_test, y_test)
print('Decision tree accuracy:', accuracy)

# Create a random forest classifier and fit it to the training data
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_estimators=100)
rf.fit(X_train, y_train)

# Evaluate the accuracy of the model on the testing data
accuracy = rf.score(X_test, y_test)
print('Random forest accuracy:', accuracy)

from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
nb.fit(X_train, y_train)

# Evaluate the accuracy of the model on the testing data
accuracy = nb.score(X_test, y_test)
print('Naive Bayes accuracy:', accuracy)

import tensorflow as tf
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential
# Create an ANN model with one hidden layer and an output layer
model = Sequential()
model.add(Dense(10, input_dim=X.shape[1], activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model on the training data
model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)

# Evaluate the accuracy of the model on the testing data
accuracy = model.evaluate(X_test, y_test, verbose=0)[1]
print('ANN accuracy:', accuracy)

y_pred=model.predict(X_test)
y_pred

y_pr=np.where(y_pred>0.5,1,0)
y_test

from sklearn.metrics import confusion_matrix, accuracy_score



# Compute the confusion matrix and accuracy score
cm = confusion_matrix(y_test, y_pr)
score = accuracy_score(y_test, y_pr)

print('Confusion Matrix:')
print(cm)
print('Accuracy Score Is: ', score*100, '%')

import pickle

def new_review(new_review_text):
    # Load the trained CountVectorizer from the saved file
    with open('/content/cv1.pkl', 'rb') as file:
        cv = pickle.load(file)

    # Preprocess the new review text
    new_review = cv.transform([new_review_text]).toarray()

    # Load the trained model from the saved file
    with open('/content/model.pkl', 'rb') as file:
        model = pickle.load(file)

    # Make a prediction on the new review text
    prediction = model.predict(new_review)

    # Return the predicted sentiment value
    return prediction[0]

import re
import numpy as np
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer

def new_review(new_review):
  new_review=new_review
  new_review = re.sub('[a-zA-Z]',' ',new_review)
  new_review = new_review.lower()
  new_review = new_review.split()
  ps = PorterStemmer()
  all_stopwords = stopwords.words('english')
  all_stopwords.remove('not')
  new_review = [ps.stem(word) for word in new_review if not word in set(all_stopwords)]
  new_review = ' '.join(new_review)
  new_corpus = [new_review]
  new_X_test = cv.transform(new_corpus).toarray()
  print(new_X_test)
  new_y_pred = model.predict(new_X_test)
  print(new_y_pred)
  new_X_pred = np.where(new_y_pred>0.5,1,0)
  return new_y_pred

new_review=new_review(str(input("Enter new review...")))

y_pred_binary = np.where(y_pred > 0.5, 1, 0)
cm = confusion_matrix(y_test, y_pred_binary)
score = accuracy_score(y_test, y_pred_binary)
print(cm)
print('accuracy score for naive bayes:', score * 100)

y_pred_binary = np.where(y_pred > 0.5, 1, 0)

from sklearn.metrics import confusion_matrix, accuracy_score

cm = confusion_matrix(y_test, y_pred_binary)
score = accuracy_score(y_test, y_pred_binary)
print(cm)
print('accuracy score:', score * 100)
print('========================================')
cm1 = confusion_matrix(y_test, y_pred_binary)
score1 = accuracy_score(y_test, y_pred_binary)
print(cm1)
print('accuracy score is:', score1 * 100)

y_pred= np.where(y_pred > 0.5, 1, 0)

from sklearn.metrics import confusion_matrix,accuracy_score
cm=confusion_matrix(y_test,y_pred)
score=accuracy_score(y_test,y_pred)
print(cm)
print('accuracy score is:-',score*100)

cm=confusion_matrix(y_test,y_pred)
score=accuracy_score(y_test,y_pred)
print(cm)
print('Accuracy Score Is:-',score*100)

pickle.dump(cv,open('spam.pkl','wb'))

model.save('spam.h5')